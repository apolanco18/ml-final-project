{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml-final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apolanco18/ml-final-project/blob/master/ml_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVpNhTCBdF-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zklbm4bVzIAH",
        "colab_type": "code",
        "outputId": "19ecfee0-fedf-46fd-c990-5f37ba1e6c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "import argparse\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "import xgboost as xgb\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "\n",
        "class ParameterTuning(object):\n",
        "  init = None\n",
        "\n",
        "\n",
        "  def __init__(self,init):\n",
        "    self.init = init\n",
        "\n",
        "  \n",
        "  def model_metrics(self,totalTime,yTrain,yHatTrain,yTest,yHat):\n",
        "    totalTime = time.time() - totalTime\n",
        "\n",
        "    trainAcc = accuracy_score(yTrain, yHatTrain)\n",
        "    testAcc = accuracy_score(yTest, yHat)\n",
        "\n",
        "    f1 = f1_score(yTest, yHat, average='macro')\n",
        "    matrix = metrics.confusion_matrix(yTest, yHat)\n",
        "\n",
        "    stats = {}\n",
        "    stats['train accuracy'] = trainAcc\n",
        "    stats['test accuracy'] = testAcc\n",
        "    stats['macro f1 score'] = f1\n",
        "    stats['time taken'] = totalTime\n",
        "\n",
        "    return stats,matrix\n",
        "\n",
        "  def print_stats(self,matrix,stats):\n",
        "    # print(matrix)\n",
        "    print('Train Accuracy {}'.format(stats['train accuracy']))\n",
        "    print('Test Accuracy {}'.format(stats['test accuracy']))\n",
        "    print('Macro F1 Score {}'.format(stats['macro f1 score']))\n",
        "    print('Time Taken {}'.format(stats['time taken']))    \n",
        "  \n",
        "\n",
        "  def testModel(self,model,xTrain, xTest, yTrain, yTest): #use this to get data on an individual model\n",
        "\n",
        "    yTrain = np.reshape(yTrain, (len(yTrain),1))\n",
        "    \n",
        "    \n",
        "    model.fit(xTrain, yTrain)\n",
        "    yHatTrain = model.predict(xTrain)\n",
        "\n",
        "    totalTime = time.time()\n",
        "    yHat = model.predict(xTest)\n",
        "\n",
        "\n",
        "    ##-----------Metrics------------------##\n",
        "\n",
        "    stats,matrix = self.model_metrics(totalTime,yTrain,yHatTrain,yTest,yHat)\n",
        "\n",
        "    return stats,matrix\n",
        "\n",
        "  def knn(self,nn,xTrain,yTrain,xTest,yTest):\n",
        "    knn = KNeighborsClassifier(n_neighbors = nn)\n",
        "\n",
        "    stats,matrix = self.testModel(knn,xTrain,xTest,yTrain,yTest)\n",
        "\n",
        "    print(\"KNN: {}\".format(nn))\n",
        "    self.print_stats(matrix,stats)\n",
        "\n",
        "    return nn,stats\n",
        "  \n",
        "  def write_knn_results(self,type,data):\n",
        "\n",
        "    filepath = '/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/Results/KNN/knn_data_' + type + '.csv'\n",
        "\n",
        "    with open(filepath, 'w') as f:\n",
        "      fileWriter = csv.writer(f,delimiter=',',quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
        "      fileWriter.writerow(['nn','train accuracy','test accuracy', 'macro f1 score','time taken'])\n",
        "      for i in range(len(data)):\n",
        "        fileWriter.writerow([data[i]['nn'],data[i]['stats']['train accuracy'],data[i]['stats']['test accuracy'],data[i]['stats']['macro f1 score'],data[i]['stats']['time taken']])\n",
        "    f.close()\n",
        "\n",
        "\n",
        "\n",
        "  def param_tuning_knn(self,type,xTrain,yTrain,xTest,yTest):\n",
        "\n",
        "    listOfData = []\n",
        "\n",
        "    for i in range(1,16):\n",
        "      nn,stats = self.knn(i,xTrain,yTrain,xTest,yTest)\n",
        "\n",
        "      finalStats = {}\n",
        "      finalStats['nn'] = nn\n",
        "      finalStats['stats'] = stats\n",
        "      listOfData.append(finalStats)\n",
        "\n",
        "\n",
        "    self.write_knn_results(type,listOfData)\n",
        "\n",
        "  \n",
        "  def logReg(self,penalty,xTrain,yTrain,xTest,yTest):\n",
        "    logReg = LogisticRegression(penalty = penalty, solver = 'lbfgs', multi_class = 'auto')\n",
        "\n",
        "    stats,matrix = self.testModel(logReg,xTrain,xTest,yTrain,yTest)\n",
        "\n",
        "    print(\"Logistic Regression - Penalty: {}\".format(penalty))\n",
        "    self.print_stats(matrix,stats)\n",
        "\n",
        "    return penalty,stats\n",
        "\n",
        "  def write_logReg_results(self,type,data):\n",
        "\n",
        "    filepath = '/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/Results/Logistic Regression/logReg_data_' + type + '.csv'\n",
        "\n",
        "    with open(filepath, 'w') as f:\n",
        "      fileWriter = csv.writer(f,delimiter=',',quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
        "      fileWriter.writerow(['penalty','train accuracy','test accuracy', 'macro f1 score','time taken'])\n",
        "      for i in range(len(data)):\n",
        "        fileWriter.writerow([data[i]['penalty'],data[i]['stats']['train accuracy'],data[i]['stats']['test accuracy'],data[i]['stats']['macro f1 score'],data[i]['stats']['time taken']])\n",
        "    f.close()\n",
        "\n",
        "  def param_tuning_logReg(self,type,xTrain,yTrain,xTest,yTest):\n",
        "\n",
        "    penalties = ['none','l2']\n",
        "\n",
        "    listOfData = []\n",
        "\n",
        "    for penalty in penalties:\n",
        "      penalty,stats = self.logReg(penalty,xTrain,yTrain,xTest,yTest)\n",
        "\n",
        "      finalStats = {}\n",
        "      finalStats['penalty'] = penalty\n",
        "      finalStats['stats'] = stats\n",
        "      listOfData.append(finalStats)\n",
        "\n",
        "    self.write_logReg_results(type,listOfData)\n",
        "\n",
        "  def dt(self,criterion,maxDepth,minLeafSample,xTrain,yTrain,xTest,yTest):\n",
        "    dt = DecisionTreeClassifier(criterion = criterion,max_depth = maxDepth, min_samples_leaf = minLeafSample)\n",
        "\n",
        "    stats,matrix = self.testModel(dt,xTrain,yTrain,xTest,yTest)\n",
        "\n",
        "    # self.print_stats(matrix,stats)\n",
        "\n",
        "    return criterion,maxDepth,minLeafSample,stats\n",
        "\n",
        "  def write_dt_results(self,type,data):\n",
        "\n",
        "    filepath = '/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/Results/Decision Tree/dt_data_' + type + '.csv'\n",
        "\n",
        "    with open(filepath, 'w') as f:\n",
        "      fileWriter = csv.writer(f,delimiter=',',quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
        "      fileWriter.writerow(['criterion','max depth','min leaf samples','train accuracy','test accuracy', 'macro f1 score','time taken'])\n",
        "      for i in range(len(data)):\n",
        "        fileWriter.writerow([data[i]['criterion'],data[i]['max depth'],data[i]['min leaf samples'],data[i]['stats']['train accuracy'],data[i]['stats']['test accuracy'],data[i]['stats']['macro f1 score'],data[i]['stats']['time taken']])\n",
        "    f.close()\n",
        "\n",
        "  def param_tuning_dt(self,type,xTrain,yTrain,xTest,yTest):\n",
        "\n",
        "    listOfData = []\n",
        "\n",
        "    for g in ['gini']:\n",
        "      for maxDepth in range(1,26):\n",
        "        for minLeafSample in range(20,101,20):\n",
        "          criterion,maxDepth,minLeafSample,stats = self.dt(g,maxDepth,minLeafSample,xTrain,yTrain,xTest,yTest)\n",
        "\n",
        "          finalStats = {}\n",
        "          finalStats['criterion'] = criterion\n",
        "          finalStats['max depth'] = maxDepth\n",
        "          finalStats['min leaf samples'] = minLeafSample\n",
        "          finalStats['stats'] = stats\n",
        "          listOfData.append(finalStats)\n",
        "\n",
        "    self.write_dt_results(type,listOfData)\n",
        "\n",
        "  \n",
        "\n",
        "  def naive(self,xTrain,yTrain,xTest,yTest):\n",
        "    nv = GaussianNB()\n",
        "\n",
        "    stats,matrix = self.testModel(nv,xTrain,xTest,yTrain,yTest)\n",
        "\n",
        "    # self.print_stats(matrix,stats)\n",
        "\n",
        "    return stats\n",
        "\n",
        "  def write_naive_results(self,type,data):\n",
        "\n",
        "    filepath = '/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/Results/Naive Bayes/naive_data_' + type + '.csv'\n",
        "\n",
        "    with open(filepath, 'w') as f:\n",
        "      fileWriter = csv.writer(f,delimiter=',',quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
        "      fileWriter.writerow(['train accuracy','test accuracy', 'macro f1 score','time taken'])\n",
        "      for i in range(len(data)):\n",
        "        fileWriter.writerow([data[i]['stats']['train accuracy'],data[i]['stats']['test accuracy'],data[i]['stats']['macro f1 score'],data[i]['stats']['time taken']])\n",
        "    f.close()\n",
        "\n",
        "\n",
        "  def param_tuning_naive(self,type,xTrain,yTrain,xTest,yTest):\n",
        "    listOfData = []\n",
        "\n",
        "\n",
        "    stats = self.naive(xTrain,yTrain,xTest,yTest)\n",
        "\n",
        "    finalStats = {}\n",
        "    finalStats['stats'] = stats\n",
        "    listOfData.append(finalStats)\n",
        "\n",
        "    self.write_naive_results(type,listOfData)\n",
        "\n",
        "  \n",
        "  def write_neural_results(self,type,data):\n",
        "\n",
        "    filepath = '/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/Results/Neural Network/neuralN_data_' + type + '.csv'\n",
        "\n",
        "    with open(filepath, 'w') as f:\n",
        "      fileWriter = csv.writer(f,delimiter=',',quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
        "      fileWriter.writerow(['train accuracy','test accuracy', 'macro f1 score','time taken'])\n",
        "      for i in range(len(data)):\n",
        "        fileWriter.writerow([data[i]['stats']['train accuracy'],data[i]['stats']['test accuracy'],data[i]['stats']['macro f1 score'],data[i]['stats']['time taken']])\n",
        "    f.close()\n",
        "\n",
        "  \n",
        "  def rf(self,numTrees,maxDepth,xTrain,yTrain,xTest,yTest):\n",
        "    rf = RandomForestClassifier(n_estimators= numTrees, max_depth= maxDepth)\n",
        "\n",
        "    stats,matrix = self.testModel(rf,xTrain, xTest, yTrain, yTest)\n",
        "\n",
        "    return numTrees, maxDepth, stats\n",
        "  \n",
        "  def write_rf_results(self,type,data):\n",
        "\n",
        "    filepath = '/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/Results/Random Forest/rf_data_' + type + '.csv'\n",
        "\n",
        "    with open(filepath, 'w') as f:\n",
        "      fileWriter = csv.writer(f,delimiter=',',quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
        "      fileWriter.writerow(['number of trees','max depth','train accuracy','test accuracy', 'macro f1 score','time taken'])\n",
        "      for i in range(len(data)):\n",
        "        fileWriter.writerow([data[i]['number of trees'],data[i]['max depth'],data[i]['stats']['train accuracy'],data[i]['stats']['test accuracy'],data[i]['stats']['macro f1 score'],data[i]['stats']['time taken']])\n",
        "    f.close()  \n",
        "\n",
        "  def param_tuning_rf(self,type,xTrain,yTrain,xTest,yTest):\n",
        "\n",
        "    listOfData = []\n",
        "\n",
        "\n",
        "    for i in range(100,201,25):\n",
        "      for maxDepth in range(2,26,2):\n",
        "          numTrees,maxDepth,stats = self.rf(i,maxDepth,xTrain,yTrain,xTest,yTest)\n",
        "\n",
        "          finalStats = {}\n",
        "          finalStats['number of trees'] = numTrees\n",
        "          finalStats['max depth'] = maxDepth\n",
        "          finalStats['stats'] = stats\n",
        "          listOfData.append(finalStats)\n",
        "\n",
        "    self.write_rf_results(type,listOfData)\n",
        "\n",
        "  \n",
        "  def xgb(self,eta,maxDepth,esti,xTrain,yTrain,xTest,yTest):\n",
        "    booster = xgb.XGBClassifier(max_depth = maxDepth,eta = eta, n_estimators = esti)\n",
        "\n",
        "    stats,matrix = self.testModel(booster,xTrain, xTest, yTrain, yTest)\n",
        "\n",
        "    return eta,maxDepth,esti,stats\n",
        "\n",
        "  def write_xgb_results(self,type,data):\n",
        "\n",
        "    filepath = '/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/Results/XGB Boost/xgb_data_' + type + '.csv'\n",
        "\n",
        "    with open(filepath, 'w') as f:\n",
        "      fileWriter = csv.writer(f,delimiter=',',quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
        "      fileWriter.writerow(['eta','max depth','number of estimators','train accuracy','test accuracy', 'macro f1 score','time taken'])\n",
        "      for i in range(len(data)):\n",
        "        fileWriter.writerow([data[i]['eta'],data[i]['max depth'],data[i]['number of estimators'],data[i]['stats']['train accuracy'],data[i]['stats']['test accuracy'],data[i]['stats']['macro f1 score'],data[i]['stats']['time taken']])\n",
        "    f.close()  \n",
        "\n",
        "  def param_tuning_xgb(self,type,xTrain,yTrain,xTest,yTest):\n",
        "\n",
        "    listOfData = []\n",
        "\n",
        "\n",
        "    for eta in [.1,.2,.3,.4]:\n",
        "      for maxDepth in range(2,8,2):\n",
        "          for esti in range(5,8,1):\n",
        "            eta,maxDepth,esti,stats = self.xgb(eta,maxDepth,esti,xTrain,yTrain,xTest,yTest)\n",
        "\n",
        "            finalStats = {}\n",
        "            finalStats['eta'] = eta\n",
        "            finalStats['max depth'] = maxDepth\n",
        "            finalStats['number of estimators'] = esti\n",
        "            finalStats['stats'] = stats\n",
        "            listOfData.append(finalStats)\n",
        "\n",
        "    self.write_xgb_results(type,listOfData)   \n",
        "          \n",
        "\n",
        "  def test_all_models(self,val,type,xTrain,yTrain,xTest,yTest):\n",
        "    if val == 1:\n",
        "      self.param_tuning_knn(type,xTrain,yTrain,xTest,yTest)\n",
        "    elif val == 2:\n",
        "      self.param_tuning_logReg(type,xTrain,yTrain,xTest,yTest)\n",
        "    elif val == 3:\n",
        "      self.param_tuning_dt(type,xTrain,yTrain,xTest,yTest)\n",
        "    elif val == 4:\n",
        "      self.param_tuning_naive(type,xTrain,yTrain,xTest,yTest)\n",
        "    elif val == 5:\n",
        "      self.param_tuning_rf(type,xTrain,yTrain,xTest,yTest)\n",
        "    elif val == 6:\n",
        "      self.param_tuning_xgb(type,xTrain,yTrain,xTest,yTest)\n",
        "    \n",
        "      \n",
        "    \n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main file to run from the command line.\n",
        "    \"\"\"\n",
        "    # set up the program to take in arguments from the command line\n",
        "    np.random.seed(0)\n",
        "\n",
        "    drive.mount('/content/drive/')\n",
        "\n",
        "    xTrain = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/xTrain.npy', encoding = 'bytes')\n",
        "    xTest = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/xTest.npy', encoding = 'bytes')\n",
        "\n",
        "    xTrainScale = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/xTrainScale.npy', encoding = 'bytes')\n",
        "    xTestScale = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/xTestScale.npy', encoding = 'bytes')\n",
        "\n",
        "    xTrainFeatElim = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/xTrainFeatElim.npy', encoding = 'bytes')\n",
        "    xTestFeatElim = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/xTestFeatElim.npy', encoding = 'bytes')\n",
        "\n",
        "    xTrainPCA = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/xTrainPCA.npy', encoding = 'bytes')\n",
        "    xTestPCA = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/xTestPCA.npy', encoding = 'bytes')\n",
        "    \n",
        "\n",
        "    yTrain = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/yTrain.npy', encoding = 'bytes')\n",
        "    yTest = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/yTest.npy', encoding = 'bytes')\n",
        "\n",
        "\n",
        "    tuning = ParameterTuning('Start')\n",
        "\n",
        "\n",
        "    types = ['norm','scale','feat-elim','pca']\n",
        "    data = [[xTrain,xTest],[xTrainScale,xTestScale],[xTrainFeatElim,xTestFeatElim],[xTrainPCA,xTestPCA]]\n",
        "\n",
        "    \n",
        "\n",
        "    '''\n",
        "      KNN Model Parameter Tuning\n",
        "\n",
        "    '''\n",
        "    # for i in range(2,3):\n",
        "    #   tuning.test_all_models(1,types[i],data[i][0],yTrain,data[i][1],yTest)\n",
        "\n",
        "    '''\n",
        "      Logistic Regression Model Parameter Tuning\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    # for i in range(0,4):\n",
        "    #   tuning.test_all_models(2,types[i],data[i][0],yTrain,data[i][1],yTest)\n",
        "\n",
        "    '''\n",
        "      Decision Tree Model Parameter Tuning\n",
        "    \n",
        "    '''\n",
        "    # for i in range(0,4):\n",
        "    #   tuning.test_all_models(3,types[i],data[i][0],yTrain,data[i][1],yTest)\n",
        "\n",
        "    '''\n",
        "      Naives Bayes Model Parameter Tuning\n",
        "    \n",
        "    '''\n",
        "    # for i in range(0,4):\n",
        "    #   tuning.test_all_models(4,types[i],data[i][0],yTrain,data[i][1],yTest)\n",
        "\n",
        "    '''\n",
        "      XGB Booster Model Parameter Tuning\n",
        "    \n",
        "    '''\n",
        "\n",
        "    # for i in range(0,4):\n",
        "    #   tuning.test_all_models(6,types[i],data[i][0],yTrain,data[i][1],yTest)\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "      Neural Network Model Parameter Tuning\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    # for i in range(0,4):\n",
        "    #   neuralN = MLPClassifier()\n",
        "\n",
        "    #   stats,matrix = tuning.testModel(neuralN,data[i][0], data[i][1], yTrain, yTest)\n",
        "      \n",
        "    #   temp = []\n",
        "    #   temp2 = {}\n",
        "    #   temp2['stats'] = stats\n",
        "    #   temp.append(temp2)\n",
        "    #   tuning.write_neural_results(types[i],temp)\n",
        "\n",
        "    '''\n",
        "      Random Forest Model Parameter Tuning\n",
        "    \n",
        "    '''\n",
        "\n",
        "    # for i in range(0,4):\n",
        "    #   tuning.test_all_models(5,types[i],data[i][0],yTrain,data[i][1],yTest)\n",
        "    \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eBp_pz3ZKfx",
        "colab_type": "code",
        "outputId": "0003d4d9-2d55-4f1f-ab9f-4212cbbe19a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "auth.authenticate_user()\n",
        "import xgboost as xgb\n",
        "\n",
        "class Preprocess(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    print(\"hello world\")\n",
        "\n",
        "\n",
        "  # Scales the data so the each feature can be compared to each other\n",
        "  def scale_data(self, xFeat):\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    return scaler.fit_transform(xFeat)\n",
        "\n",
        "  \n",
        "  # Calculate Pearson Correlation Matrix \n",
        "  def pearsonMatrix(self,xFeat):\n",
        "      featCol = []\n",
        "\n",
        "      for i in range(len(xFeat[0])):\n",
        "        featCol.append(xFeat[:,i])\n",
        "      \n",
        "      pearsonMatrix = np.corrcoef(featCol)\n",
        "\n",
        "      return pearsonMatrix\n",
        "\n",
        "  \n",
        "  def graphMatrix(self,matrix):\n",
        "    sns.set()\n",
        "\n",
        "    ax = sns.heatmap(matrix)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  # Follows the idea of Feature elimination where a pearson correlation matrix is calculated and then the highly correlated features are dropped reduce the number of features\n",
        "  def feature_elimination(self,xFeat):\n",
        "\n",
        "    matrix = self.pearsonMatrix(xFeat)\n",
        "    \n",
        "    deleteColBool = np.full( (1, len(xFeat[0])), True)\n",
        "\n",
        "    deleteColBool = deleteColBool[0]\n",
        "\n",
        "    for i in range(len(xFeat[0])):\n",
        "      for t in range(i+1, len(xFeat[0])):\n",
        "        if (abs(matrix[i,t]) >= .75):\n",
        "          deleteColBool[t] = False\n",
        "\n",
        "    deleteColIndex = []\n",
        "\n",
        "    for i in range(len(deleteColBool)):\n",
        "        if (deleteColBool[i] == False):\n",
        "            deleteColIndex.append(i)\n",
        "\n",
        "    xFeat = np.delete(xFeat,deleteColIndex,axis = 1)\n",
        "\n",
        "\n",
        "    return xFeat\n",
        "\n",
        "\n",
        "  def pca(self,xFeatTrain,xFeatTest):\n",
        "    model = PCA(.95)\n",
        "\n",
        "    model.fit(xFeatTrain)\n",
        "\n",
        "    self.graph_variance_pca(model)\n",
        "\n",
        "    xTrainReduce = model.transform(xFeatTrain)\n",
        "    xTestReduce = model.transform(xFeatTest)\n",
        "\n",
        "    return xTrainReduce,xTestReduce\n",
        "\n",
        "  def graph_variance_pca(self,model):\n",
        "    plt.plot(np.cumsum(model.explained_variance_ratio_))\n",
        "    plt.xlabel('Number of Components')\n",
        "    plt.ylabel('Cumulative Explained Variance')\n",
        "  \n",
        "  def graph_pca_components(self,xFeat,yFeat):\n",
        "    xAxis = xFeat[:,0]\n",
        "    yAxis = xFeat[:,1]\n",
        "\n",
        "    labels = yFeat \n",
        "\n",
        "    colorDict = {0:'red',1:'green',2:'black',3:'yellow',4:'#1004fb',5:'cyan',6:'magenta',7:'green',8:'#e1341e',9:'#3820df',10:'#d52ad1'}\n",
        "\n",
        "    label = {0:'Benign',1:'Ack',2:'Combo',3:'Junk',4:'Scan 1',5:'Scan',6:'Syn 1',7:'Tcp',8:'Udp 1',9:'Udp',10:'Udp Plain 1'}\n",
        "\n",
        "    marker = {0:'*',1:'o',2:'.',3:'v',4:'1',5:'8',6:'s',7:'p',8:'P',9:'h',10:'x'}\n",
        "\n",
        "    alpha = {0:.3,1:.5,2:.7,3:.9,4:1.1,5:1.3,6:1.5,7:1.7,8:1.9,9:2.1,10:2.3}\n",
        "\n",
        "    fig,ax = plt.subplots(figsize = (7,5))\n",
        "    fig.patch.set_facecolor('white')\n",
        "\n",
        "    for l in np.unique(labels):\n",
        "      if l == 4:\n",
        "        break\n",
        "      ix = np.where(labels == l) \n",
        "      ax.scatter(xAxis[ix],yAxis[ix], c = colorDict[l],s = 40, label = label[l],marker = marker[l], alpha = .5)\n",
        "\n",
        "    plt.xlabel(\"First Principal Component\",fontsize=14)\n",
        "    plt.ylabel(\"Second Principal Component\",fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  \n",
        "  def write_data_file(self,name,data):\n",
        "    filepath = '/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/' + name + '.npy'\n",
        "    with open(filepath, 'w') as f:\n",
        "      np.save(f.name,data)\n",
        "      f.close()\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "  drive.mount('/content/drive/')\n",
        "\n",
        "  xTrain = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/xTrain.npy', encoding = 'bytes')\n",
        "  xTest = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/xTest.npy', encoding = 'bytes')\n",
        "  yTrain = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/yTrain.npy', encoding = 'bytes')\n",
        "  yTest = np.load('/content/drive/My Drive/19-20SchoolYear/CS334/Machine Learning Project/yTest.npy', encoding = 'bytes')\n",
        "\n",
        "\n",
        "  preprocess = Preprocess()\n",
        "\n",
        "\n",
        "  xTrainScale = preprocess.scale_data(xTrain)\n",
        "  xTestScale = preprocess.scale_data(xTest)\n",
        "\n",
        "  # Training and Test data features reduce using pearson correlation matrix for feature elimination\n",
        "  xTrainFeatElim = preprocess.feature_elimination(xTrainScale)\n",
        "  xTestFeatElim = preprocess.feature_elimination(xTestScale)\n",
        "\n",
        "\n",
        "  # preprocess.graphMatrix(preprocess.pearsonMatrix(xTrainScale))\n",
        "  # preprocess.graphMatrix(preprocess.pearsonMatrix(xTestScale))\n",
        "\n",
        "  # preprocess.graphMatrix(preprocess.pearsonMatrix(xTrainFeatElim))\n",
        "  # preprocess.graphMatrix(preprocess.pearsonMatrix(xTestFeatElim))\n",
        "\n",
        "  xTrainPCA,xTestPCA = preprocess.pca(xTrainScale,xTestScale)\n",
        "\n",
        "  preprocess.write_data_file('xTrainScale',xTrainScale)\n",
        "  preprocess.write_data_file('xTestScale',xTestScale)\n",
        "\n",
        "  preprocess.write_data_file('xTrainFeatElim',xTrainFeatElim)\n",
        "  preprocess.write_data_file('xTestFeatElim',xTestFeatElim)\n",
        "  \n",
        "  preprocess.write_data_file('xTrainPCA',xTrainPCA)\n",
        "  preprocess.write_data_file('xTestPCA',xTestPCA)\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  # preprocess.graph_pca_components(xTrainPCA,yTrain)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f9e5045ed474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuthorizationError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mauthorization\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \"\"\"\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GOOGLE_APPLICATION_CREDENTIALS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_adc_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_check_adc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mcreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_google_auth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0m_google_auth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultCredentialsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(scopes, request)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchecker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcredentials\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwith_scopes_if_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscopes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0m_get_gcloud_sdk_credentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0m_get_gae_credentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         lambda: _get_gce_credentials(request))\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchecker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36m_get_gce_credentials\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Get the project ID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/compute_engine/_metadata.py\u001b[0m in \u001b[0;36mping\u001b[0;34m(request, timeout)\u001b[0m\n\u001b[1;32m     72\u001b[0m         response = request(\n\u001b[1;32m     73\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_METADATA_IP_ROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_METADATA_HEADERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             timeout=timeout)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmetadata_flavor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_METADATA_FLAVOR_HEADER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/transport/_http_client.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, url, method, body, headers, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             connection.request(\n\u001b[0;32m--> 104\u001b[0;31m                 method, path, body=body, headers=headers, **kwargs)\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1253\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1298\u001b[0m             \u001b[0;31m# default charset of iso-8859-1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\\r\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 946\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    947\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Aq-O8rEMwEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}